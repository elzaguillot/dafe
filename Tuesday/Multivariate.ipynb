{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analytics for engineers \n",
    "\n",
    "\n",
    "\n",
    "In this tutorial we will see:\n",
    "- Exploration of multivariate datasets\n",
    "- Dimension reduction techniques (PCA)\n",
    "- Clustering methods\n",
    "\n",
    "We will use the following libraries:\n",
    "- `sklearn` \n",
    "- `scipy`\n",
    "- `pandas`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, decomposition, cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data['data'],columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "df.species=data.target_names[data.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the main information from the table above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Let's visualise the distribution of each of the four variables: petal length, petal width, sepal length, sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at these distribution for each of the three species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g=df[data.target==0].boxplot()\n",
    "plt.title(data.target_names[0])\n",
    "plt.show(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g=df[data.target==1].boxplot()\n",
    "plt.title(data.target_names[1])\n",
    "plt.show(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g=df[data.target==2].boxplot()\n",
    "plt.title(data.target_names[2])\n",
    "plt.show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's visualise the relationship between each pair of variables. Because there are 4 variables, we need to represent 6 pairs of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_width,df.petal_length)\n",
    "plt.xlabel(\"petal width\")\n",
    "plt.ylabel(\"petal length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_width,df.sepal_width)\n",
    "plt.xlabel(\"petal width\")\n",
    "plt.ylabel(\"sepal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_width,df.sepal_length)\n",
    "plt.xlabel(\"petal width\")\n",
    "plt.ylabel(\"sepal length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_length,df.sepal_length)\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"sepal length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.sepal_width,df.sepal_length)\n",
    "plt.xlabel(\"sepal width\")\n",
    "plt.ylabel(\"sepal length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all these plot describe the variables and how they are linked to the species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation `r` is a measure of **association between two variables**. It takes a values between -1 and 1:\n",
    "- $r<0$ = negative association (if one variable increases the other one decreases)\n",
    "- $r>0$ = positive association (if one variable increases the other one increases as well)\n",
    "- $r=0$ = no association between the variables\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$$ r= \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})}\\sqrt{\\sum(y_i-\\bar{y})}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what the correlation above mean. Which variables seem to be the most similar? dissimilar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reduction\n",
    "\n",
    "In the Iris dataset has 4 variables. For many reasons we may want to reduce the information into 2 dimensions only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimension reduction method. Each sample is project onto two dimensions, as well as each variable. The two dimension are built to retain as much information as possible, (in statistical term maximize the variance).\n",
    "\n",
    "The first step before doing a pca is to standardized the variables, i.e. transform all data so that each variable has a mean of $0$ and a standard deviation of $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=StandardScaler().fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the effect of the standardisation on the data using a boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do the PCA using `decompisition.PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_pca = decomposition.PCA(n_components=2)# create a pca\n",
    "principalComponents = iris_pca.fit_transform(x) # fit the pca to this dataset\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC1', 'PC2'])# save the output \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA has a set of outputs, that are all informative, that we will look at in details. It can be analysis based solely on numbers or based on plots.\n",
    "\n",
    "Doing a PCA we project sample in $k=2$ (or more) dimensions, instead of the orginal $p$ dimensions. This creates two new variables (or axis or PC). These PCs are linear combination of the original variables:\n",
    "\n",
    "$PC1=a_1\\times sepal.length + b_1\\times sepal.width +c_1 \\times petal.length + d_1 \\times petal.width$\n",
    "\n",
    "$PC2=a_2\\times sepal.length + b_2\\times sepal.width +c_2 \\times petal.length + d_2 \\times petal.width$\n",
    "\n",
    "The first element of this method is to know how much of the orginal information (variance) is maintained by keeping only $k$ dimensions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output tells us that PC1 represents 72.8% of the original variance and PC2 23.0% of the orginal variance. Hence in total, by using two variables (PC1 and PC2) instead of the original four variables, we keep 95.8%  of the information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs gives us the relative value of each original variable on te new PC1 and PC2.  They are basically the $a$,$b$,$c$ and $d$ of the previous equation so:\n",
    "\n",
    "$PC1=0.52\\times sepal.length -0.26\\times sepal.width +0.58 \\times petal.length + 0.56 \\times petal.width$\n",
    "\n",
    "$PC2=0.37\\times sepal.length + 0.92\\times sepal.width =0.021\\times petal.length +0.065 \\times petal.width$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the first PC is mostly influenced by the all measures and the second PC is mostly influenced by the sepal width.\n",
    "\n",
    "Now let's look at how the flowers are projected into the 2 new dimensions. The following dataframe contains the coordinates of each sample in the new dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principalDf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually easier to represent all this information via plots, to undertansd what is happening in the data. First we can plot all the samples against the new dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(principalDf.PC1,principalDf.PC2)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.xlabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`principalDf` now contains the new coordinate of each sample in the new two dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how the species matches the new coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==0],c=\"r\",label=data.target_names[0])\n",
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==1],c=\"b\",label=data.target_names[1])\n",
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==2],c=\"g\",label=data.target_names[2])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==0],c=\"r\",label=data.target_names[0])\n",
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==1],c=\"b\",label=data.target_names[1])\n",
    "plt.scatter(\"PC1\",\"PC2\",data=principalDf[data.target==2],c=\"g\",label=data.target_names[2])\n",
    "for i in range(4):\n",
    "    plt.arrow(0,0,iris_pca.components_[0][i],iris_pca.components_[1][i])\n",
    "    plt.text(iris_pca.components_[0][i],iris_pca.components_[1][i],data.feature_names[i])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"IRIS PCA\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last plot, which is the main output of PCA, show that setosas plant are different than versicolor and virgonica. They have smaller petal width and length, and smaller sepal length.\n",
    "It also show that virginica are largely bigger than versicolor.\n",
    "\n",
    "From this we can identify which are the important variable in separating different type of flowers. This is a first step towards clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: on a separate notebook, read the dataset `databeer.csv` perform a small exploration and a PCA on the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clustering\n",
    "\n",
    "PCA was the first step towards clusering, i.e. grouping samples that are most alike. There exists many clustering methods but we will cover only two main ones: hierarchical clustering and k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hierarchical cluster\n",
    "\n",
    "Hierarchical clustering methods are a set of methods that join individuals that are the closest to each other to form clusters, until all individuals are joined in  $k$ clusters, $k$ being the desired number of cluster. In some implementation it is not always necessary to specify $k$ beofre running the algorithm, but in `scikit` it is.\n",
    "\n",
    "There are different variation of the method, based on the *linkage* method, i.e. how do you define  the distance between two clusters. In scikit there are 3 methods available `complete` `ward` and  `average`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycluster = cluster.AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete')  \n",
    "mycluster.fit_predict(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster attribution for each sample can be found in the `mycluster` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycluster.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the results, by coloring each sample by its cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clust1=np.where(mycluster.labels_==0) ## the rows of all individuals that belong to cluster 1\n",
    "clust2=np.where(mycluster.labels_==1) ## the rows of all individuals that belong to cluster 2\n",
    "clust3=np.where(mycluster.labels_==2) ## the rows of all individuals that belong to cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.sepal_length.iloc[clust1],df.sepal_width.iloc[clust1],label=\"cluster 1\",c=\"b\")\n",
    "plt.scatter(df.sepal_length.iloc[clust2],df.sepal_width.iloc[clust2],label=\"cluster 1\",c=\"r\")\n",
    "plt.scatter(df.sepal_length.iloc[clust3],df.sepal_width.iloc[clust3],label=\"cluster 1\",c=\"g\")\n",
    "plt.legend()\n",
    "plt.title(\"Kmean clustering of Iris\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_length.iloc[clust1],df.petal_width.iloc[clust1],label=\"cluster 1\",c=\"b\")\n",
    "plt.scatter(df.petal_length.iloc[clust2],df.petal_width.iloc[clust2],label=\"cluster 1\",c=\"r\")\n",
    "plt.scatter(df.petal_length.iloc[clust3],df.petal_width.iloc[clust3],label=\"cluster 1\",c=\"g\")\n",
    "plt.legend()\n",
    "plt.title(\"Kmean clustering of Iris\")\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Petal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you see above, and the characteristics of each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a new  clustering by using another linkage method `ward` or `average` and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means\n",
    "\n",
    "Kmean is a heuristics algorithm. Given a dataset with p variable, you must tell the algorithm how many cluster you want.\n",
    "\n",
    "For the Iris dataset, we want to find 3 different group of plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans= cluster.KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the kmean instance, we fit it to te data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is 3 clusters. Each of them has a center with coordinates in the 4 original dimensions. Each sample is now assigned to a cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_ # the coordinates of the center, i.e. their value for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.labels_ # the cluster attributed to each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clust1=np.where(kmeans.labels_==0) ## the rows of all individuals that belong to cluster 1\n",
    "clust2=np.where(kmeans.labels_==1) ## the rows of all individuals that belong to cluster 2\n",
    "clust3=np.where(kmeans.labels_==2) ## the rows of all individuals that belong to cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.sepal_length.iloc[clust1],df.sepal_width.iloc[clust1],label=\"cluster 1\",c=\"b\")\n",
    "plt.scatter(df.sepal_length.iloc[clust2],df.sepal_width.iloc[clust2],label=\"cluster 1\",c=\"r\")\n",
    "plt.scatter(df.sepal_length.iloc[clust3],df.sepal_width.iloc[clust3],label=\"cluster 1\",c=\"g\")\n",
    "plt.legend()\n",
    "plt.title(\"Kmean clustering of Iris\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.petal_length.iloc[clust1],df.petal_width.iloc[clust1],label=\"cluster 1\",c=\"b\")\n",
    "plt.scatter(df.petal_length.iloc[clust2],df.petal_width.iloc[clust2],label=\"cluster 1\",c=\"r\")\n",
    "plt.scatter(df.petal_length.iloc[clust3],df.petal_width.iloc[clust3],label=\"cluster 1\",c=\"g\")\n",
    "plt.legend()\n",
    "plt.title(\"Kmean clustering of Iris\")\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Petal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you see above, and the characteristic of each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compare these clusters to the known species, by doing a cross tabulation of the variables that contains the cluster for each sample, and the one that contains the species for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species=data.target_names[data.target]\n",
    "clust=kmeans.labels_\n",
    "pd.crosstab(clust,species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all setosa belong to cluster 1, Versicolor are mostly in cluster 0 and virginica are mostly in cluster 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: repeat this last operation for the neighbour joining result. Conclude on which algorithm is the best in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercice: Perform a cluster of the beer dataset, on the same notebook that you created for PCA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits dataset\n",
    "\n",
    "Digits recognition is now automatically performed with clusting method. Do a PCA and a cluster analysis of the digits dataset. Check how well your model predict the digit. ( you may want to do it on a sperate notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd=datasets.load_digits()\n",
    "print(dd[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
